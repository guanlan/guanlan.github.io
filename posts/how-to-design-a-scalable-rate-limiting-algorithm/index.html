<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>How to Design a Scalable Rate Limiting Algorithm - Guanlan Dai</title><meta name=Description content="This is my cool site"><meta property="og:url" content="https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/"><meta property="og:site_name" content="Guanlan Dai"><meta property="og:title" content="How to Design a Scalable Rate Limiting Algorithm"><meta property="og:description" content="What is rate limiting? Rate limiting protects your APIs from inadvertent or malicious overuse by limiting how often each user can call the API. Without rate limiting, each user may make a request as often as they like, leading to “spikes” of requests that starve other consumers. Once enabled, rate limiting can only perform a fixed number of requests per second. A rate limiting algorithm helps automate the process."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-01-15T12:19:18+08:00"><meta property="article:modified_time" content="2021-01-15T12:19:18+08:00"><meta property="article:tag" content="Kong"><meta property="article:tag" content="Rate Limiting"><meta name=twitter:card content="summary"><meta name=twitter:title content="How to Design a Scalable Rate Limiting Algorithm"><meta name=twitter:description content="What is rate limiting? Rate limiting protects your APIs from inadvertent or malicious overuse by limiting how often each user can call the API. Without rate limiting, each user may make a request as often as they like, leading to “spikes” of requests that starve other consumers. Once enabled, rate limiting can only perform a fixed number of requests per second. A rate limiting algorithm helps automate the process."><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/><link rel=prev href=https://rmmod.com/posts/effective-web-crawler/><link rel=next href=https://rmmod.com/posts/kong-gateway-rate-limiting/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"How to Design a Scalable Rate Limiting Algorithm","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/rmmod.com\/posts\/how-to-design-a-scalable-rate-limiting-algorithm\/"},"genre":"posts","keywords":"Kong, Rate Limiting","wordcount":2453,"url":"https:\/\/rmmod.com\/posts\/how-to-design-a-scalable-rate-limiting-algorithm\/","datePublished":"2021-01-15T12:19:18+08:00","dateModified":"2021-01-15T12:19:18+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"guanlan"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Guanlan Dai">Guanlan Dai</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/>Home </a><a class=menu-item href=/about/>About </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Guanlan Dai">Guanlan Dai</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/ title>Home</a><a class=menu-item href=/about/ title>About</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">How to Design a Scalable Rate Limiting Algorithm</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>guanlan</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2021-01-15>2021-01-15</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;2453 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;12 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#what-is-rate-limiting>What is rate limiting?</a></li><li><a href=#why-is-rate-limiting-used>Why is rate limiting used?</a></li><li><a href=#what-kind-of-attacks-can-rate-limiting-prevent>What kind of attacks can rate limiting prevent?</a></li><li><a href=#how-do-you-enable-rate-limiting>How do you enable rate limiting?</a></li><li><a href=#rate-limiting-algorithms>Rate limiting algorithms</a><ul><li><a href=#leaky-bucket>Leaky Bucket</a></li><li><a href=#fixed-window>Fixed Window</a></li><li><a href=#sliding-log>Sliding Log</a></li><li><a href=#sliding-window>Sliding Window</a></li></ul></li><li><a href=#rate-limiting-in-distributed-systems>Rate limiting in distributed systems</a><ul><li><a href=#synchronization-policies>Synchronization Policies</a></li><li><a href=#race-conditions>Race Conditions</a></li><li><a href=#optimizing-for-performance>Optimizing for Performance</a></li></ul></li><li><a href=#quickly-set-up-rate-limiting-with-kong-api-gateway>Quickly set up rate limiting with Kong API Gateway</a><ul><li><a href=#adding-an-api-on-kong-gateway>Adding an API on Kong Gateway</a></li><li><a href=#adding-basic-rate-limiting>Adding Basic Rate-Limiting</a></li></ul></li><li><a href=#better-performance-with-advanced-rate-limiting-and-konnect>Better performance with advanced rate limiting and Konnect</a></li></ul></nav></div></div><div class=content id=content><h2 id=what-is-rate-limiting>What is rate limiting?</h2><p>Rate limiting protects your APIs from inadvertent or malicious overuse by limiting how often each user can call the API. Without rate limiting, each user may make a request as often as they like, leading to &ldquo;spikes&rdquo; of requests that starve other consumers. Once enabled, rate limiting can only perform a fixed number of requests per second. A rate limiting algorithm helps automate the process.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/01-rate-limit-kong.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/01-rate-limit-kong.png, https://konghq.com/wp-content/uploads/2017/12/01-rate-limit-kong.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/01-rate-limit-kong.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/01-rate-limit-kong.png title="rate limiting enabled at 2 requests/min"></p><p>In the example chart, you can see how rate limiting blocks requests over time. The API was initially receiving four requests per minute, shown in green. When we enabled rate limiting at 12:02, the system denied additional requests, shown in red.</p><h2 id=why-is-rate-limiting-used>Why is rate limiting used?</h2><p>Rate limiting is very important for public APIs where you want to maintain a good quality of service for every consumer, even when some users take more than their fair share. Computationally-intensive endpoints are particularly in need of rate limiting &mdash; especially when served by auto-scaling, or by pay-by-the-computation services like <a href=https://docs.konghq.com/hub/kong-inc/aws-lambda target=_blank rel="noopener noreffer">AWS Lambda</a>. You also may want to rate limit APIs that serve sensitive data because this could limit the data exposed if an attacker gains access in some unforeseen event.</p><p>Rate limiting can be used to accomplish the following:</p><ul><li>Avoid resource starvation: Rate limiting can improve the availability of services and help avoid friendly-fire denial-of-service (DoS) attacks.</li><li>Cost management: Rate limiting can be used to enforce cost controls, (for example) preventing surprise bills from experiments or misconfigured resources .</li><li>Manage policies and quotas: Rate limiting allows for the fair sharing of a service with multiple users.</li><li>Control flow: For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data. It can allow for the merging of multiple streams into one service or the equally distribution of a single stream to multiple workers.</li><li>Security: Rate limiting can be used as defense or mitigation against some common attacks.</li></ul><h2 id=what-kind-of-attacks-can-rate-limiting-prevent>What kind of attacks can rate limiting prevent?</h2><p>Rate limiting can be critical in protecting against a variety of bot-based attacks, including:</p><ul><li>DoS and DDoS (distributed denial-of-service) attacks</li><li>Brute force and credential stuffing attacks</li><li>Web scraping or site scraping</li></ul><h2 id=how-do-you-enable-rate-limiting>How do you enable rate limiting?</h2><p>There are many different ways to enable rate limiting, and we will explore the pros and cons of varying rate limiting algorithms. We will also explore the issues that come up when scaling across a cluster. Lastly, we&rsquo;ll show you an example of how to quickly set up rate limiting using <a href=https://konghq.com/kong target=_blank rel="noopener noreffer">Kong Gateway</a>, which is the most popular open-source <a href=https://konghq.com/learning-center/api-gateway/what-is-an-api-gateway target=_blank rel="noopener noreffer">API gateway</a>.</p><p>Want to set up rate limiting for your API gateway with clicks instead of code? <a href=https://konghq.com/kong-konnect target=_blank rel="noopener noreffer">Try Konnect for free &#187;</a></p><p>If you&rsquo;re interested in rate limiting for <a href=https://konghq.com/solutions/kubernetes-ingress target=_blank rel="noopener noreffer">Kubernetes</a> services, check out this video:</p><h2 id=rate-limiting-algorithms>Rate limiting algorithms</h2><p>There are various algorithms for API rate limiting, each with its benefits and drawbacks. Let&rsquo;s review each of them so you can pick the ideal rate limiting design option for your API needs.</p><h3 id=leaky-bucket>Leaky Bucket</h3><p><a href=https://en.wikipedia.org/wiki/Leaky_bucket target=_blank rel="noopener noreffer">Leaky bucket</a> (closely related to <a href=https://en.wikipedia.org/wiki/Token_bucket target=_blank rel="noopener noreffer">token bucket</a>) is an algorithm that provides a simple, intuitive approach to rate limiting via a queue, which you can think of as a bucket holding the requests. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first in, first out (FIFO). If the queue is full, then additional requests are discarded (or leaked).</p><p><img class=lazyload src=/svg/loading.min.svg data-src="https://kongwp.imgix.net/wp-content/uploads/2017/12/02-rate-limit-kong.png?auto=compress%2Cformat" data-srcset="https://kongwp.imgix.net/wp-content/uploads/2017/12/02-rate-limit-kong.png?auto=compress%2Cformat, https://kongwp.imgix.net/wp-content/uploads/2017/12/02-rate-limit-kong.png?auto=compress%2Cformat 1.5x, https://kongwp.imgix.net/wp-content/uploads/2017/12/02-rate-limit-kong.png?auto=compress%2Cformat 2x" data-sizes=auto alt="https://kongwp.imgix.net/wp-content/uploads/2017/12/02-rate-limit-kong.png?auto=compress%2Cformat" title="rate limiting capacity"></p><p>This algorithm&rsquo;s advantage is that it smooths out bursts of requests and processes them at an approximately average rate. It&rsquo;s also easy to implement on a single server or<a href=https://konghq.com/blog/dear-load-balancers target=_blank rel="noopener noreffer"> load balancer</a> and is memory efficient for each user, given the limited queue size.</p><p>However, a burst of traffic can fill up the queue with old requests and starve more recent requests from being processed. It also provides no guarantee that requests get processed in a fixed amount of time. Additionally, if you load balance servers for fault tolerance or increased throughput, you must use a policy to coordinate and enforce the limit between them. We will come back to the challenges of distributed environments later.</p><h3 id=fixed-window>Fixed Window</h3><p>The system uses a window size of n seconds (typically using human-friendly values, such as 60 or 3600 seconds) to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold. The current timestamp floor typically defines the windows, so 12:00:03, with a 60-second window length, would be in the 12:00:00 window.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/03-rate-limit-kong.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/03-rate-limit-kong.png, https://konghq.com/wp-content/uploads/2017/12/03-rate-limit-kong.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/03-rate-limit-kong.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/03-rate-limit-kong.png title="request 3 denied"></p><p>This algorithm&rsquo;s advantage is that it ensures more recent requests get processed without being starved by old requests. However, a single burst of traffic that occurs near the boundary of a window can result in the processing of twice the rate of requests because it will allow requests for both the current and next windows within a short time. Additionally, if many consumers wait for a reset window, they may stampede your API at the same time at the top of the hour.</p><h3 id=sliding-log>Sliding Log</h3><p>Sliding Log rate limiting involves tracking a time-stamped log for each consumer&rsquo;s request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.</p><p><img class=lazyload src=/svg/loading.min.svg data-src="https://kongwp.imgix.net/wp-content/uploads/2017/12/04-rate-limit-kong.png?auto=compress%2Cformat" data-srcset="https://kongwp.imgix.net/wp-content/uploads/2017/12/04-rate-limit-kong.png?auto=compress%2Cformat, https://kongwp.imgix.net/wp-content/uploads/2017/12/04-rate-limit-kong.png?auto=compress%2Cformat 1.5x, https://kongwp.imgix.net/wp-content/uploads/2017/12/04-rate-limit-kong.png?auto=compress%2Cformat 2x" data-sizes=auto alt="https://kongwp.imgix.net/wp-content/uploads/2017/12/04-rate-limit-kong.png?auto=compress%2Cformat" title="request at 12:00:35 hold"></p><p>The advantage of this algorithm is that it does not suffer from the boundary conditions of fixed windows. Enforcement of the rate limit will remain precise. Since the system tracks the sliding log for each consumer, you don&rsquo;t have the stampede effect that challenges fixed windows. However, it can be costly to store an unlimited number of logs for every request. It&rsquo;s also expensive to compute because each request requires calculating a summation over the consumer&rsquo;s prior requests, potentially across a cluster of servers. As a result, it does not scale well to handle large bursts of traffic or denial of service attacks.</p><h3 id=sliding-window>Sliding Window</h3><p>Sliding Window is a hybrid approach that combines the fixed window algorithm&rsquo;s low processing cost and the sliding log&rsquo;s improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window&rsquo;s request rate based on the current timestamp to smooth out bursts of traffic. For example, if the current window is 25% through, we weigh the previous window&rsquo;s count by 75%. The relatively small number of data points needed to track per key allows us to scale and distribute across large clusters.</p><p><img class=lazyload src=/svg/loading.min.svg data-src="https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat" data-srcset="https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat, https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat 1.5x, https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat 2x" data-sizes=auto alt="https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat" title="https://kongwp.imgix.net/wp-content/uploads/2017/12/05-rate-limit-kong.png?auto=compress%2Cformat"></p><p>We recommend the sliding window approach because it gives the flexibility to scale rate limiting with good performance. The rate windows are an intuitive way to present rate limit data to API consumers. It also avoids the starvation problem of the leaky bucket and the bursting problems of fixed window implementations.</p><h2 id=rate-limiting-in-distributed-systems>Rate limiting in distributed systems</h2><h3 id=synchronization-policies>Synchronization Policies</h3><p>If you want to enforce a global rate limit when using a <a href=https://konghq.com/learning-center/api-gateway/api-gateways-for-high-availability-clusters target=_blank rel="noopener noreffer">cluster of multiple nodes</a>, you must set up a policy to <a href=https://konghq.com/blog/using-instaclustr-and-cassandra-with-kong target=_blank rel="noopener noreffer">enforce it</a>. If each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.</p><p>The simplest way to enforce the limit is to set up sticky sessions in your load balancer so that each consumer gets sent to exactly one node. The disadvantages include a lack of fault tolerance and scaling problems when nodes get overloaded.</p><p>A better solution that allows more flexible load-balancing rules is to use a centralized data store such as Redis or<a href=https://konghq.com/blog/using-instaclustr-and-cassandra-with-kong target=_blank rel="noopener noreffer"> Cassandra</a>. A centralized data store will collect the counts for each window and consumer. The two main problems with this approach are increased latency making requests to the data store and race conditions, which we will discuss next.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/06-rate-limit-kong.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/06-rate-limit-kong.png, https://konghq.com/wp-content/uploads/2017/12/06-rate-limit-kong.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/06-rate-limit-kong.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/06-rate-limit-kong.png title="load balancer requests going into nodes"></p><h3 id=race-conditions>Race Conditions</h3><p>One of the most extensive problems with a centralized data store is the potential for <a href=https://en.wikipedia.org/wiki/Race_condition target=_blank rel="noopener noreffer">race conditions</a> in <a href=https://en.wikipedia.org/wiki/Concurrency_%28computer_science%29 target=_blank rel="noopener noreffer">high concurrency</a> request patterns. This issue happens when you use a naïve &ldquo;get-then-set&rdquo; approach, wherein you retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model&rsquo;s problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very high rate of requests to bypass rate limiting controls.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/06-2-rate-limit-kong.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/06-2-rate-limit-kong.png, https://konghq.com/wp-content/uploads/2017/12/06-2-rate-limit-kong.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/06-2-rate-limit-kong.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/06-2-rate-limit-kong.png title="load balancer requests going into nodes and then counter to Redis"></p><p>One way to avoid this problem is to put a &ldquo;lock&rdquo; around the key in question, preventing any other processes from accessing or writing to the counter. A lock would quickly become a significant performance bottleneck and does not scale well, mainly when using remote servers like Redis as the backing datastore.</p><p>A better approach is to use a &ldquo;set-then-get&rdquo; mindset, relying on atomic operators that implement locks in a very performant fashion, allowing you to quickly increment and check counter values without letting the atomic operations get in the way.</p><h3 id=optimizing-for-performance>Optimizing for Performance</h3><p>The increased <a href=https://konghq.com/blog/observability-kubernetes-kong target=_blank rel="noopener noreffer">latency</a> is another disadvantage of using a centralized data store when checking the rate limit counters. Unfortunately, even checking a fast data store like Redis would result in milliseconds of additional latency for every request.</p><p>Make checks locally in memory to make these rate limit determinations with minimal latency. To make local checks, relax the rate check conditions and use an eventually consistent model. For example, each node can create a data sync cycle that will synchronize with the centralized data store. Each node periodically pushes a counter increment for each consumer and window to the datastore. These pushes atomically update the values. The node can then retrieve the updated values to update its in-memory version. This cycle of converge → diverge → reconverge among nodes in the cluster is eventually consistent.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png, https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png title=https://konghq.com/wp-content/uploads/2017/12/07-rate-limit-kong.png></p><p>The periodic rate at which nodes converge should be configurable. Shorter sync intervals will result in less divergence of data points when spreading traffic across multiple nodes in the cluster (e.g., when sitting behind a round robin balancer). Whereas longer sync intervals put less read/write pressure on the datastore and less overhead on each node to fetch new synced values.</p><h2 id=quickly-set-up-rate-limiting-with-kong-api-gateway>Quickly set up rate limiting with Kong API Gateway</h2><p>Kong is an <a href=https://konghq.com/kong target=_blank rel="noopener noreffer">open source API gateway</a> that makes it very easy to build scalable services with rate limiting. It scales perfectly from single Kong Gateway nodes to massive, globe-spanning Kong clusters.</p><p>Kong Gateway sits in front of your APIs and is the main entry point to your upstream APIs. While processing the request and the response, Kong Gateway will execute any plugin that you have decided to add to the API.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://konghq.com/wp-content/uploads/2017/12/illustration2.png data-srcset="https://konghq.com/wp-content/uploads/2017/12/illustration2.png, https://konghq.com/wp-content/uploads/2017/12/illustration2.png 1.5x, https://konghq.com/wp-content/uploads/2017/12/illustration2.png 2x" data-sizes=auto alt=https://konghq.com/wp-content/uploads/2017/12/illustration2.png title="kong gateway"></p><p>Kong API Gateway&rsquo;s rate limiting plug-in is highly configurable. It:</p><ul><li>Offers flexibility to define multiple rate limit windows and rates for each API and consumer</li><li>Includes support for local memory, Redis, Postgres, and Cassandra backing datastores</li><li>Offers a variety of data synchronization options, including synchronous and eventually consistent models</li></ul><p>You can quickly <a href=https://konghq.com/install#kong-gateway target=_blank rel="noopener noreffer">try Kong Gateway</a> on one of your dev machines to test it out. My favorite way to get started is to use the <a href=https://getkong.org/install/aws-cloudformation target=_blank rel="noopener noreffer">AWS cloud formation template</a> since I get a pre-configured dev machine in just a few clicks. Just choose one of the HVM options, and set your instance sizes to use t2.micro as these are affordable for testing. Then ssh into a command line on your new instance for the next step.</p><h3 id=adding-an-api-on-kong-gateway>Adding an API on Kong Gateway</h3><p>The next step is <a href=https://konghq.com/blog/set-up-kong-gateway target=_blank rel="noopener noreffer">adding an API</a> on Kong Gateway using the admin API, which can be done by setting up a Route and a Service entity. We will use <a href=https://httpbin.org/ target=_blank rel="noopener noreffer">httpbin</a>, a free testing service for APIs, as our example upstream service,. The get URL will mirror back my request data as JSON. We also assume Kong Gateway is running on the local system at the default ports.</p><pre><code class=bash>curl  -i  -X  POST
  --url http://localhost:8001/services/
  --data  &#39;name=httpbin
  --data &#39;url=http://httpbin.org/get&#39;

curl  -i  -X  POST
  --url http://localhost:8001/services/httpbin/routes
  --data  &#39;paths[]=/test&#39;</code></pre><p>Now Kong Gateway is aware that every request sent to &ldquo;/test&rdquo; should be proxied to httpbin. We can make the following request to Kong Gateway on its proxy port to test it:</p><pre><code class=bash>curl http://localhost:8000/test
{
&#34;args&#34;:  {},
&#34;headers&#34;:  {
&#34;Accept&#34;:  &#34;*/*&#34;,
&#34;Connection&#34;:  &#34;close&#34;,
&#34;Host&#34;:  &#34;httpbin.org&#34;,
&#34;User-Agent&#34;:  &#34;curl/7.51.0&#34;,
&#34;X-Forwarded-Host&#34;:  &#34;localhost&#34;
},
&#34;origin&#34;:  &#34;localhost, 52.89.171.202&#34;,
&#34;url&#34;:  &#34;http://localhost/get&#34;
}</code></pre><p>It&rsquo;s alive! Kong Gateway received the request and proxied it to httpbin, which has mirrored back the headers for my request and my origin IP address.</p><h3 id=adding-basic-rate-limiting>Adding Basic Rate-Limiting</h3><p>Let&rsquo;s go ahead and protect it from an excessive number of requests by adding the rate-limiting functionality using the community edition <a href=https://getkong.org/plugins/rate-limiting target=_blank rel="noopener noreffer">Rate-Limiting plugin</a>, with a limit of 5 requests per minute from every consumer:</p><pre><code class=bash>curl  -i  -X  POST http://localhost:8001/services/httpbin/plugins/
-d  &#34;name=rate-limiting&#34;
-d  &#34;config.minute=5&#34;</code></pre><p>If we now make more than five requests, Kong Gateway will respond with the following error message:</p><pre><code class=bash>curl http://localhost:8000/test
{
&#34;message&#34;:&#34;API rate limit exceeded&#34;
}</code></pre><p>Looking good! We have added an API on Kong Gateway, and we added rate-limiting in just two HTTP requests to the admin API.</p><p>It defaults to rate limiting by IP address using fixed windows and synchronizes across all nodes in your cluster using your default datastore. For other options, including rate limiting per consumer or using another datastore like Redis, please see the <a href=https://getkong.org/plugins/rate-limiting target=_blank rel="noopener noreffer">documentation</a>.</p><p>For a more detailed tutorial, check out <a href=https://konghq.com/blog/kong-gateway-rate-limiting target=_blank rel="noopener noreffer">Protecting Services With Kong Gateway Rate Limiting &#187;</a></p><h2 id=better-performance-with-advanced-rate-limiting-and-konnect>Better performance with advanced rate limiting and Konnect</h2><p>The <a href=https://docs.konghq.com/hub/kong-inc/rate-limiting-advanced target=_blank rel="noopener noreffer">Advanced Rate Limiting plugin</a> adds support for the sliding window algorithm for better control and performance. The sliding window prevents your API from being overloaded near window boundaries, as explained in the sections above. For low latency, it uses an in-memory table of the counters and can synchronize across the cluster using asynchronous or synchronous updates. This gives the latency of local thresholds and is scalable across your entire cluster.</p><p>The first step is <a href=https://konghq.com/kong-konnect target=_blank rel="noopener noreffer">start a free trial of Konnect</a>. You can then configure the rate limit, the window size in seconds, and how often to sync the counter values. It&rsquo;s straightforward to use, and you can get this robust control with a simple API call:</p><pre><code class=bash>curl  -i  -X  POST http://localhost:8001/services/httpbin/plugins
-d  &#34;name=rate-limiting&#34;
-d  &#34;config.limit=5&#34;
-d  &#34;config.window_size=60&#34;
-d  &#34;config.sync_rate=10&#34;</code></pre><p>The enterprise edition also supports Redis Sentinel, which makes Redis highly available and more fault-tolerant. You can read more in the <a href=https://docs.konghq.com/hub/kong-inc/rate-limiting target=_blank rel="noopener noreffer">rate limiting plugin documentation</a>.</p><p>Other features include an admin GUI, more security features like role-based access control, analytics and professional support. If you&rsquo;re interested in learning more about the Enterprise edition, just <a href=https://konghq.com/contact target=_blank rel="noopener noreffer">contact</a> Kong&rsquo;s sales team to <a href=https://konghq.com/request-demo target=_blank rel="noopener noreffer">request a demo</a>.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2021-01-15</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on X" data-sharer=x data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm" data-via=guanlandai data-hashtags="Kong,Rate Limiting"><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Threads" data-sharer=threads data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm"><i class="fab fa-threads fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-hashtag=Kong><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@14.9.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Diaspora" data-sharer=diaspora data-url=https://rmmod.com/posts/how-to-design-a-scalable-rate-limiting-algorithm/ data-title="How to Design a Scalable Rate Limiting Algorithm" data-description><i class="fab fa-diaspora fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2frmmod.com%2fposts%2fhow-to-design-a-scalable-rate-limiting-algorithm%2f&amp;text=How%20to%20Design%20a%20Scalable%20Rate%20Limiting%20Algorithm" target=_blank title="Share on Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/kong/>Kong</a>,&nbsp;<a href=/tags/rate-limiting/>Rate Limiting</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/effective-web-crawler/ class=prev rel=prev title="Practical Tips on Writing an Effective Web Crawler"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Practical Tips on Writing an Effective Web Crawler</a>
<a href=/posts/kong-gateway-rate-limiting/ class=next rel=next title="Protecting Services With Kong Gateway Rate Limiting">Protecting Services With Kong Gateway Rate Limiting<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Guanlan Dai | CC BY-NC 4.0</div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2009 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>Guanlan Dai</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script>window.config={comment:{}}</script><script src=/js/theme.min.js></script></body></html>